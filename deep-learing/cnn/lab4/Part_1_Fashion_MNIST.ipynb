{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg2hLK7hlWdb"
      },
      "source": [
        "# Lab 4 - Part 1: Classifying Fashion-MNIST\n",
        "\n",
        "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1ZmqLpNTQSW2fhWaxtZRxlyd8G6BbN8Pa' width=400px> </center>\n",
        "\n",
        "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebooks though as you work through this.\n",
        "\n",
        "First of all, let's import our resources and download the Fashion-MNIST dataset from `tensorflow_datasets`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMflYTIOtOPf"
      },
      "source": [
        "## Import resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mEVFxa8WYM_j"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U0n2QWj1p2fG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-09 14:09:09.700431: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-09 14:09:09.703067: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-09 14:09:09.712419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-09 14:09:09.729047: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-09 14:09:09.733416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-09 14:09:09.743972: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-09 14:09:11.458324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UQyLYltaYM_k"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FwP1_Qw-cCsY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using:\n",
            "\t• TensorFlow version: 2.17.0\n",
            "\t• GPU device not found. Running on CPU\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1728475768.517057    5083 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-09 14:09:28.977459: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "print('Using:')\n",
        "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
        "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr2SOjl8txrZ"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "We are now going to load the Fashion-MNIST dataset using `tensorflow_datasets` as we've done before. In this case, however, we are going to omit the `split` argument.  This means that `tensorflow_datasets` will use the default value for `split` which is `split=None`. When `split=None`, `tensorflow_datasets` returns a **dictionary** with all the splits available for the dataset you are loading. However, if the split is given explicitly, such as `split='train'`, then `tensorflow_datasets` returns a `tf.data.Dataset` object.\n",
        "\n",
        "In our case, we are going to load the `fashion_mnist` dataset. If we look at the [documentation](https://www.tensorflow.org/datasets/catalog/fashion_mnist#statistics) we will see that this particular dataset has 2 splits, namely a `train` and a `test` split. We also see that the `train` split has 60,000 examples, and that the `test` split has 10,000 examples.\n",
        "\n",
        "Now, let's load the `fashion_mnist` dataset and inspect the returned values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1kn4Op7dXCnk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-09 14:10:27.234972: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /home/etudiants/chau5/tensorflow_datasets/fashion_mnist/3.0.1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1728475835.123930    5083 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-09 14:10:35.127046: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset fashion_mnist downloaded and prepared to /home/etudiants/chau5/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "dataset, dataset_info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2_vT6HUUXg05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset has type: <class 'dict'>\n",
            "\n",
            "The keys of dataset are: [Split('train'), Split('test')]\n"
          ]
        }
      ],
      "source": [
        "# Check that dataset is a dictionary\n",
        "print('dataset has type:', type(dataset))\n",
        "\n",
        "# Print the keys of the dataset dictionary\n",
        "print('\\nThe keys of dataset are:', list(dataset.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S4f2J9jbpak"
      },
      "source": [
        "In the cell below, we are going to save the training data and the test data into different variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kxo7PHJys18t"
      },
      "outputs": [],
      "source": [
        "training_set, test_set = dataset['train'], dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzZciG_KcHbI"
      },
      "source": [
        "Now, let's take a look at the `dataset_info`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7jFE3vbebU-A"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='fashion_mnist',\n",
              "    full_name='fashion_mnist/3.0.1',\n",
              "    description=\"\"\"\n",
              "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
              "    \"\"\",\n",
              "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
              "    data_dir=PosixGPath('/tmp/tmptzk1o926tfds'),\n",
              "    file_format=tfrecord,\n",
              "    download_size=29.45 MiB,\n",
              "    dataset_size=36.42 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
              "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
              "    },\n",
              "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
              "      author    = {Han Xiao and\n",
              "                   Kashif Rasul and\n",
              "                   Roland Vollgraf},\n",
              "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
              "                   Algorithms},\n",
              "      journal   = {CoRR},\n",
              "      volume    = {abs/1708.07747},\n",
              "      year      = {2017},\n",
              "      url       = {http://arxiv.org/abs/1708.07747},\n",
              "      archivePrefix = {arXiv},\n",
              "      eprint    = {1708.07747},\n",
              "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
              "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
              "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the dataset_info\n",
        "dataset_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_If36cti685"
      },
      "source": [
        "We can access the information in `dataset_info` very easily. As we can see, the `features` and `splits` info are contained in dictionaries. We can access the information we want by accessing the particular key and value in these dictionaries. We start by looking at the values of particular keys in these dictionaries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uiOf0aqlYM_l"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Image(shape=(28, 28, 1), dtype=uint8)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_info.features['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-n1acmAbYM_l"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassLabel(shape=(), dtype=int64, num_classes=10)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_info.features['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iA3Q-1ktYM_l"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<SplitInfo num_examples=60000, num_shards=1>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_info.splits['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PsDR7iOVYM_m"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<SplitInfo num_examples=10000, num_shards=1>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_info.splits['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFwhpPOijumG"
      },
      "source": [
        "We can now use `dot` notation to access the information we want. Below are some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m9_OYPHsbbcl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 10 classes in our dataset.\n",
            "The images in our dataset have shape: (28, 28, 1)\n",
            "\n",
            "There are 10,000 images in the test set.\n",
            "There are 60,000 images in the training set.\n"
          ]
        }
      ],
      "source": [
        "shape_images = dataset_info.features['image'].shape\n",
        "num_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "num_training_examples  = dataset_info.splits['train'].num_examples\n",
        "num_test_examples = dataset_info.splits['test'].num_examples\n",
        "\n",
        "print('There are {:,} classes in our dataset.'.format(num_classes))\n",
        "print('The images in our dataset have shape:', shape_images)\n",
        "\n",
        "print('\\nThere are {:,} images in the test set.'.format(num_test_examples))\n",
        "print('There are {:,} images in the training set.'.format(num_training_examples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfMgIb3PvWXo"
      },
      "source": [
        "## Explore the dataset\n",
        "\n",
        "The images in this dataset are 28 $\\times$ 28 arrays, with pixel values in the range `[0, 255]`. The *labels* are an array of integers, in the range `[0, 9]`. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. Since the *class names* are not included with the dataset, we create them here to use later when plotting the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "odzN3aJjusED"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RoY1HeJJyces"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The images in the training set have:\n",
            "• dtype: <dtype: 'uint8'> \n",
            "• shape: (28, 28, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-09 14:14:32.629529: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
            "2024-10-09 14:14:32.630163: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "for image, label in training_set.take(1):\n",
        "    print('The images in the training set have:\\n\\u2022 dtype:', image.dtype, '\\n\\u2022 shape:', image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CInprnnJ1_gk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-09 14:14:52.122936: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
            "2024-10-09 14:14:52.123866: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 248,
              "width": 305
            },
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The label of this image is: 2\n",
            "The class name of this image is: Pullover\n"
          ]
        }
      ],
      "source": [
        "for image, label in training_set.take(1):\n",
        "    image = image.numpy().squeeze()\n",
        "    label = label.numpy()\n",
        "\n",
        "plt.imshow(image, cmap= plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "print('The label of this image is:', label)\n",
        "print('The class name of this image is:', class_names[label])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-lmuTM35C9"
      },
      "source": [
        "## Create pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3gq-_mXl3ZFG"
      },
      "outputs": [],
      "source": [
        "def normalize(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "training_batches = training_set.cache().shuffle(num_training_examples//4).batch(batch_size).map(normalize).prefetch(1)\n",
        "testing_batches = test_set.cache().batch(batch_size).map(normalize).prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LviX4-ii8js7"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "> **Exercise:** Here you should define your own neural network. Feel free to create a model with as many layers and neurons as you like. You should keep in mind that as with MNIST, each image is 28 $\\times$ 28 which is a total of 784 pixels, and there are 10 classes. Your model should include at least one hidden layer. We suggest you use ReLU activation functions for the hidden layers and a softmax activation function for the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYzFZ3jQ8azd"
      },
      "outputs": [],
      "source": [
        "## Solution\n",
        "model = ####\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYhwsFzA-Aah"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "> **Exercise:** Compile the model you created above using an `adam` optimizer, a `sparse_categorical_crossentropy` loss function, and the `accuracy` metric. Then train the model for 5 epochs. You should be able to get the training loss below 0.4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cyy9SqTU91IS"
      },
      "outputs": [],
      "source": [
        "## Solution\n",
        "model.compile(optimizer= ##,\n",
        "              loss= ##,\n",
        "              metrics= ###\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(training_batches,epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REJbwplUBoRT"
      },
      "source": [
        "## Evaluate loss and accuracy on the test set\n",
        "\n",
        "Now let's see how the model performs on the test set. This time, we will use all the examples in our test set to assess the loss and accuracy of our model. Remember, the images in the test are images the model has never seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q76aDGGl_xp4"
      },
      "outputs": [],
      "source": [
        "# your solution here\n",
        "loss, accuracy = model.evaluate(###)\n",
        "\n",
        "print('\\nLoss on the TEST Set: {:,.3f}'.format(loss))\n",
        "print('Accuracy on the TEST Set: {:.3%}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnpZWDQp2Zaq"
      },
      "source": [
        "## Check predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqUzc4pYAe7Z"
      },
      "outputs": [],
      "source": [
        "for image_batch, label_batch in testing_batches.take(1):\n",
        "    ps = model.predict(image_batch)\n",
        "    first_image = image_batch.numpy().squeeze()[0]\n",
        "    first_label = label_batch.numpy()[0]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "ax1.imshow(first_image, cmap = plt.cm.binary)\n",
        "ax1.axis('off')\n",
        "ax1.set_title(class_names[first_label])\n",
        "ax2.barh(np.arange(10), ps[0])\n",
        "ax2.set_aspect(0.1)\n",
        "ax2.set_yticks(np.arange(10))\n",
        "ax2.set_yticklabels(class_names, size='small');\n",
        "ax2.set_title('Class Probability')\n",
        "ax2.set_xlim(0, 1.1)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA34NavohwTs"
      },
      "source": [
        "## Try all steps above using your `CNN Network`\n",
        "Compare your results in DNN vs CNN network : you need to build and train your CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbXRz5MTYM_q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
