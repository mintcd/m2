%%TITRE
\begin{center}
    \textbf{\Large RESPONSIBLE AND TRUSTED ARTIFICIAL INTELLIGENCE} \\
    \vspace{0.5cm}

    Miniconference Report \\
    CHAU Dang Minh
\end{center}

\section{EU AI Act}

Artificial intelligence (AI) can create many benefits, such as better healthcare; safer and cleaner transport; more efficient manufacturing; and cheaper and more sustainable energy. However, most AI models are statistical learners, hence mistakes are possible, even at an infinitesimal percentage. For vital decisions, a single mistake is not allowed. As part of its digital strategy, the EU wants to regulate AI to ensure better conditions for the development and use of this innovative technology. In April 2021, the European Commission proposed the first EU regulatory framework for AI. It says that AI systems that can be used in different applications are analyzed and classified according to the risk they pose to users. The different risk levels will mean more or less regulation, including

\begin{enumerate}
    \item Unacceptable Risk: AI applications banned outright, such as social scoring by governments or real-time biometric surveillance in public spaces (with certain exceptions).
    \item High Risk: AI systems requiring strict oversight, including: Critical infrastructure, Education and training, etc.
    \item Limited Risk: Systems requiring specific transparency obligations (e.g., chatbots must disclose they are AI).
    \item Minimal or No Risk: No specific regulatory obligations, covering most consumer AI applications like video games or spam filters.
\end{enumerate}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{img/risks.png}
    \caption{Possible AI risks}
\end{figure}


\section{Responsibility Labeling}
AI Act compliance comes with a cost for AI engineering company if they want to ensure by themselves. Besides, any future accidents can result in judiciary responsibility. Responsibility assessment organizations, like Labelia, are established to minimize this cost. The assessment process has been developed carefully through years, starting from lawyers' manual assessment to automatization, and finally open sourcing. Such assessment plays a crucial role in the development of efficient while responsible AI models.

\section{Conclusion}

Learning laws for AI is not directly relevant to our courses. However, it helps us firstly to decide right actions when engineering AI models, and secondly to express an adequate knowledge in AI beyond technical problems when interviewing with employers.